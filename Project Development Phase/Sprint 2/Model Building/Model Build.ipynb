{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9347f6a8",
   "metadata": {},
   "source": [
    "# ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "85d3ea1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "train_datagen=ImageDataGenerator(rescale=1./255,shear_range=0.2,zoom_range=0.2,horizontal_flip=True)\n",
    "test_datagen=ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e43588ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "train='E:\\Team Lead\\conversation engine for deaf and dumb\\Dataset\\\\training_set'\n",
    "test='E:\\Team Lead\\conversation engine for deaf and dumb\\Dataset\\\\test_set'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "404b231a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 15750 images belonging to 9 classes.\n"
     ]
    }
   ],
   "source": [
    "x_train = train_datagen.flow_from_directory(train, target_size=(64,64), batch_size=300,\n",
    "                                            class_mode=\"categorical\", color_mode = \"grayscale\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "44be2c51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2250 images belonging to 9 classes.\n"
     ]
    }
   ],
   "source": [
    "x_test = test_datagen.flow_from_directory(test, target_size=(64,64), batch_size=300, class_mode=\"categorical\", color_mode = \"grayscale\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a34dc35f",
   "metadata": {},
   "source": [
    "# Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "126ea8b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Convolution2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e00ac9c9",
   "metadata": {},
   "source": [
    "# Initialize model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5b7f11d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0f1d81d",
   "metadata": {},
   "source": [
    "## Convolution Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "29689b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Convolution2D(32,(3,3),input_shape=(64,64,1), activation='relu'))\n",
    "#no. of feature detectors, size of feature detector, image size, activation function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39df58bb",
   "metadata": {},
   "source": [
    "# Add The Pooling Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "46c84f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(MaxPooling2D(pool_size=(2,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3448d7e9",
   "metadata": {},
   "source": [
    "# Add The Flatten Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "49753a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c998fb45",
   "metadata": {},
   "source": [
    "# Adding The Dense Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "60ef6d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(units=512, activation='relu')) #Adding_The_Dense_Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0e94676b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(units=9,activation='softmax'))#Adding_The_Pooling_Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee146525",
   "metadata": {},
   "source": [
    "# Compile The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3631965d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"categorical_crossentropy\",optimizer=\"adam\",metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e23071d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 62, 62, 32)        320       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 31, 31, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 30752)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               15745536  \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 9)                 4617      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 15,750,473\n",
      "Trainable params: 15,750,473\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "143e9566",
   "metadata": {},
   "source": [
    "# Fit And Save The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f56775a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\GarenaIT\\AppData\\Local\\Temp\\ipykernel_5536\\690709108.py:1: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  model.fit_generator(x_train,steps_per_epoch=24,epochs=10,validation_data=x_test,validation_steps=40 )\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "24/24 [==============================] - ETA: 0s - loss: 1.3308 - accuracy: 0.6389WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 40 batches). You may need to use the repeat() function when building your dataset.\n",
      "24/24 [==============================] - 128s 5s/step - loss: 1.3308 - accuracy: 0.6389 - val_loss: 0.4798 - val_accuracy: 0.8889\n",
      "Epoch 2/10\n",
      "24/24 [==============================] - 57s 2s/step - loss: 0.3277 - accuracy: 0.9089\n",
      "Epoch 3/10\n",
      "24/24 [==============================] - 42s 2s/step - loss: 0.1636 - accuracy: 0.9600\n",
      "Epoch 4/10\n",
      "24/24 [==============================] - 33s 1s/step - loss: 0.1078 - accuracy: 0.9722\n",
      "Epoch 5/10\n",
      "24/24 [==============================] - 36s 2s/step - loss: 0.0662 - accuracy: 0.9822\n",
      "Epoch 6/10\n",
      "24/24 [==============================] - 33s 1s/step - loss: 0.0551 - accuracy: 0.9860\n",
      "Epoch 7/10\n",
      "24/24 [==============================] - 38s 2s/step - loss: 0.0444 - accuracy: 0.9892\n",
      "Epoch 8/10\n",
      "24/24 [==============================] - 34s 1s/step - loss: 0.0322 - accuracy: 0.9929\n",
      "Epoch 9/10\n",
      "24/24 [==============================] - 33s 1s/step - loss: 0.0233 - accuracy: 0.9954\n",
      "Epoch 10/10\n",
      "24/24 [==============================] - 35s 1s/step - loss: 0.0229 - accuracy: 0.9947\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2cd4da1b6d0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(x_train,steps_per_epoch=24,epochs=10,validation_data=x_test,validation_steps=40 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84665343",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"IBM.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
